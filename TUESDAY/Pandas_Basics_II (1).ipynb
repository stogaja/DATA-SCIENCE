{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pandas Basics II",
      "provenance": [],
      "collapsed_sections": [
        "v2Rb2q_Epd9P",
        "5b5cMg9vpg3D",
        "juUUmvj5r1U1",
        "UvgWwvdBpxIF",
        "9_XCQAP5sF5r",
        "C2opvjY3p6zc",
        "BfpO_aWfsXXQ",
        "IwxDABvUp97g",
        "66Fjm3xmslG7",
        "7jHC3c0jqFHy",
        "yOI_UEXDs0XI"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I110jHWZkwL"
      },
      "source": [
        "<font color=\"green\">*To start working on this notebook, or any other notebook that we will use in the Moringa Data Science Course, we will need to save our own copy of it. We can do this by clicking File > Save a Copy in Drive. We will then be able to make edits to our own copy of this notebook.*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YW4SN5OupJfN"
      },
      "source": [
        "# Pandas Basics II\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2Rb2q_Epd9P"
      },
      "source": [
        "## 1.0 Importing the Libraries to be used "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frw-YOvjpCiw"
      },
      "source": [
        "# Let's import the pandas library\n",
        "#\n",
        "# OUR CODE GOES HERE\n",
        "import pandas as pd\n",
        "# as well as the Numpy library\n",
        "import numpy as np\n",
        "\n",
        "# OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b5cMg9vpg3D"
      },
      "source": [
        "## 1.1 Loading our Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9gmYBvxptCI"
      },
      "source": [
        "# Example 1\n",
        "# We will begin learning how we can load datasets from different types of sources\n",
        "# Let's first begin with loading datasets from a JSON file \n",
        "#\n",
        "\n",
        "\n",
        "# First, we get the URL to the JSON file (alternatively this can be a filepath)\n",
        "url = 'https://raw.githubusercontent.com/algolia/datasets/master/airports/airports.json'\n",
        "\n",
        "# Then load, the first sheet of the JSON file into a data frame. \n",
        "# We are going to use pandas read_json method. This method works the same as read_csv. You can read more about it from the documentation: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_json.html\n",
        "df = pd.read_json(url, orient='columns')\n",
        "\n",
        "# Lastly, view the first ten rows\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaY5MQdxptu0"
      },
      "source": [
        "# Example 2\n",
        "# We can also load an Excel file as shown below\n",
        "# \n",
        "\n",
        "# We create a URL to Excel file (alternatively this can be a filepath)\n",
        "url = 'https://raw.githubusercontent.com/chrisalbon/simulated_datasets/master/data.xlsx'\n",
        "\n",
        "# Then load the first sheet of the Excel file into a data frame\n",
        "df = pd.read_excel(url, sheetname=0, header=1)\n",
        "\n",
        "# Lastly, view the first ten rows\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfmKllkvptir"
      },
      "source": [
        "# Example 3\n",
        "# We can also load A CSV Into pandas\n",
        "# \n",
        "\n",
        "# We create a csv file or import from a url\n",
        "\n",
        "# First, creating a dataframe (that we will be importing)\n",
        "raw_data = {'first_name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n",
        "        'last_name': ['Miller', 'Jacobson', \".\", 'Milner', 'Cooze'], \n",
        "        'age': [42, 52, 36, 24, 73], \n",
        "        'preTestScore': [4, 24, 31, \".\", \".\"],\n",
        "        'postTestScore': [\"25,000\", \"94,000\", 57, 62, 70]}\n",
        "df = pd.DataFrame(raw_data, columns = ['first_name', 'last_name', 'age', 'preTestScore', 'postTestScore'])\n",
        "df\n",
        "\n",
        "# Saving the above dataframe as csv in the working directory\n",
        "df.to_csv('example.csv')\n",
        "\n",
        "# Loading a csv\n",
        "# df = pd.read_csv('example.csv')\n",
        "# df\n",
        "\n",
        "# Loading a csv with no headers\n",
        "# Uncomment the lines below after running previous lines.\n",
        "# df = pd.read_csv('example.csv', header=None) \n",
        "# df\n",
        "\n",
        "# Loading a csv while specifying column names\n",
        "# Uncomment the lines below after running previous lines.\n",
        "# df = pd.read_csv('example.csv', names=['UID', 'First Name', 'Last Name', 'Age', 'Pre-Test Score', 'Post-Test Score'])\n",
        "# df\n",
        "\n",
        "# Loading a csv while setting the index columns to First Name and Last Name\n",
        "# Uncomment the lines below after running previous lines.\n",
        "# df = pd.read_csv('example.csv', index_col=['First Name', 'Last Name'], names=['UID', 'First Name', 'Last Name', 'Age', 'Pre-Test Score', 'Post-Test Score'])\n",
        "# df\n",
        "\n",
        "# Loading a csv while specifying “.” and “NA” as missing values in the Last Name column and “.” as missing values in Pre-Test Score column\n",
        "# Uncomment the lines below after running previous lines.\n",
        "sentinels = {'Last Name': ['.', 'NA'], 'Pre-Test Score': ['.']}\n",
        "df = pd.read_csv('example.csv', na_values=sentinels)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juUUmvj5r1U1"
      },
      "source": [
        "### <font color=\"green\">1.1 Challenges</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OSrlmj2r-vR"
      },
      "source": [
        "# Challenge 1\n",
        "# Load the first 10 records of the JSON file from the following url\n",
        "# url = https://raw.githubusercontent.com/dariusk/corpora/master/data/books/academic_subjects.json\n",
        "# \n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLAQVIq-sAWZ"
      },
      "source": [
        "# Challenge 2\n",
        "# Preview the excel spreadsheet from the following url\n",
        "# url = http://ww2.amstat.org/publications/jse/v20n3/delzell/conflictdata.xlsx\n",
        "# \n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obhaE1tisAOE"
      },
      "source": [
        "# Challenge 3\n",
        "# Download and upload the csv file from this url (http://bit.ly/NairobiBusesDataset) (Not Load from Url)\n",
        "# Then preview the dataset while specifying column names \n",
        "# \n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk1pYV6pbTEK"
      },
      "source": [
        "# Challenge 4 \n",
        "# Create a Dataframe from the following dictionary then fill in the missing values with \".\"\n",
        "#\n",
        "\n",
        "# Dictionary\n",
        "dict = {'First Score':[100, 90, np.nan, 95], \n",
        "        'Second Score': [30, 45, 56, np.nan], \n",
        "        'Third Score':[np.nan, 40, 80, 98]} \n",
        "\n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvgWwvdBpxIF"
      },
      "source": [
        "## 1.2 Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3E_v5OjSpzZa"
      },
      "source": [
        "# Example 1\n",
        "# We will now see how we can filter pandas Dataframes as shown below\n",
        "# \n",
        "\n",
        "# Creating the following Dataframe\n",
        "data = {'name': ['Kevin', 'Jane', 'Mary', 'Jared', 'Elizabeth'], \n",
        "        'year': [2012, 2012, 2013, 2014, 2014], \n",
        "        'reports': [4, 24, 31, 2, 3],\n",
        "        'coverage': [25, 94, 57, 62, 70]}\n",
        "df = pd.DataFrame(data, index = ['Nairobi', 'Nakuru', 'Kisumu', 'Kericho', 'Eldoret'])\n",
        "df\n",
        "\n",
        "# Viewing a column\n",
        "# Uncomment the line below after running previous line\n",
        "# df['name']\n",
        "\n",
        "# Viewing two Columns\n",
        "# Uncomment the line below after running previous line\n",
        "# df[['name', 'reports']]\n",
        "\n",
        "# Viewing the first two Rows\n",
        "# Uncomment the line below after running previous line\n",
        "# df[:2]\n",
        "\n",
        "# Viewing rows where coverage is greater than 50\n",
        "# Uncomment the line below after running previous line\n",
        "# df[df['coverage'] > 50]\n",
        "\n",
        "\n",
        "# Viewing rows where coverage is greater than 50 and reports less than 4\n",
        "# Uncomment the line below after running previous line\n",
        "# df[(df['coverage']  > 50) & (df['reports'] < 4)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R-B-0cwp0t5"
      },
      "source": [
        "# Example 2\n",
        "# Then find the largest value in a Dataframe column\n",
        "# \n",
        "\n",
        "# First creating a Dataframe\n",
        "raw_data = {'first_name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n",
        "        'last_name': ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze'], \n",
        "        'age': [42, 52, 36, 24, 73], \n",
        "        'preTestScore': [4, 24, 31, 2, 3],\n",
        "        'postTestScore': [25, 94, 57, 62, 70]}\n",
        "df = pd.DataFrame(raw_data, columns = ['first_name', 'last_name', 'age', 'preTestScore', 'postTestScore'])\n",
        "df\n",
        "\n",
        "# Then Indexing of the row with the highest value in the preTestScore column\n",
        "# Uncomment the line below after running previous line\n",
        "# df['preTestScore'].max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esmZmojypz0a"
      },
      "source": [
        "# Example 3\n",
        "# Finding also Unique Values In the Pandas Dataframes\n",
        "import numpy as np\n",
        "\n",
        "# First creating a Dataframe from a Dictionary\n",
        "raw_data = {'regiment': ['51st', '29th', '2nd', '19th', '12th', '101st', '90th', '30th', '193th', '1st', '94th', '91th'], \n",
        "            'trucks': ['MAZ-7310', np.nan, 'MAZ-7310', 'MAZ-7310', 'Tatra 810', 'Tatra 810', 'Tatra 810', 'Tatra 810', 'ZIS-150', 'Tatra 810', 'ZIS-150', 'ZIS-150'],\n",
        "            'tanks': ['Merkava Mark 4', 'Merkava Mark 4', 'Merkava Mark 4', 'Leopard 2A6M', 'Leopard 2A6M', 'Leopard 2A6M', 'Arjun MBT', 'Leopard 2A6M', 'Arjun MBT', 'Arjun MBT', 'Arjun MBT', 'Arjun MBT'],\n",
        "            'aircraft': ['none', 'none', 'none', 'Harbin Z-9', 'Harbin Z-9', 'none', 'Harbin Z-9', 'SH-60B Seahawk', 'SH-60B Seahawk', 'SH-60B Seahawk', 'SH-60B Seahawk', 'SH-60B Seahawk']}\n",
        "df = pd.DataFrame(raw_data, columns = ['regiment', 'trucks', 'tanks', 'aircraft'])\n",
        "df\n",
        "\n",
        "# Viewing the top few rows\n",
        "# Uncomment the line below after running previous lines\n",
        "# df.head()\n",
        "\n",
        "# We can create a list of unique values by turning the pandas column into a set\n",
        "# Uncomment the line below after running previous lines\n",
        "# list(set(df.trucks))\n",
        "\n",
        "# Here's another way of creating a list of unique values in df.trucks\n",
        "# Uncomment the line below after running previous lines\n",
        "# list(df['trucks'].unique())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3RH0pXqqRbH"
      },
      "source": [
        "# Example 4\n",
        "# listing Unique Values In A pandas Column\n",
        "#\n",
        "\n",
        "# Create an example dataframe\n",
        "data = {'name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n",
        "        'year': [2012, 2012, 2013, 2014, 2014], \n",
        "        'reports': [4, 24, 31, 2, 3]}\n",
        "df = pd.DataFrame(data, index = ['Cochice', 'Pima', 'Santa Cruz', 'Maricopa', 'Yuma'])\n",
        "df\n",
        "\n",
        "# List unique values in the df['name'] column\n",
        "# Uncomment the line below after running previous lines\n",
        "# df.name.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcCOrEo5qpfS"
      },
      "source": [
        "# Example 5\n",
        "# Grouping Rows In pandas\n",
        "# \n",
        "\n",
        "# Creating a Dataframe\n",
        "raw_data = {'regiment': ['Nighthawks', 'Nighthawks', 'Nighthawks', 'Nighthawks', 'Dragoons', 'Dragoons', 'Dragoons', 'Dragoons', 'Scouts', 'Scouts', 'Scouts', 'Scouts'], \n",
        "        'company': ['1st', '1st', '2nd', '2nd', '1st', '1st', '2nd', '2nd','1st', '1st', '2nd', '2nd'], \n",
        "        'name': ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze', 'Jacon', 'Ryaner', 'Sone', 'Sloan', 'Piger', 'Riani', 'Ali'], \n",
        "        'preTestScore': [4, 24, 31, 2, 3, 4, 24, 31, 2, 3, 2, 3],\n",
        "        'postTestScore': [25, 94, 57, 62, 70, 25, 94, 57, 62, 70, 62, 70]}\n",
        "df = pd.DataFrame(raw_data, columns = ['regiment', 'company', 'name', 'preTestScore', 'postTestScore'])\n",
        "df\n",
        "\n",
        "# Creating a grouping object. In other words, create an object that\n",
        "# represents that particular grouping. In this case we group\n",
        "# pre-test scores by the regiment.\n",
        "# Uncomment the line below after running previous lines\n",
        "# regiment_preScore = df['preTestScore'].groupby(df['regiment'])\n",
        "\n",
        "# Displaying the mean value of the each regiment's pre-test score\n",
        "# Uncomment the line below after running previous lines\n",
        "# regiment_preScore.mean()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_XCQAP5sF5r"
      },
      "source": [
        "### <font color=\"green\"> 1.2 Challenges</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_MYzHTPsFWe"
      },
      "source": [
        "# Challenge 1\n",
        "# Let us view the following Dataframe upon creation from the following Dictionary\n",
        "#\n",
        "data = {'name': ['Alice', 'Robert', 'Charles', 'David', 'Eric'],\n",
        "        'year of joining': [2014, 2015, 2013, 2014, 2013],\n",
        "        'salary': [40000, 25000, 35000, 200000, 30000]}\n",
        "df = pd.DataFrame(data, index = ['I&M', 'I&M', 'KCB', 'KCB', 'KCB'])\n",
        "df\n",
        "\n",
        "# Let us view salary column\n",
        "OUR CODE GOES HERE\n",
        "\n",
        "# We would like to compare the name and the salary columns\n",
        "# OUR CODE GOES HERE\n",
        "\n",
        "# Let's view the first three records of the dataframe\n",
        "# OUR CODE GOES HERE\n",
        "\n",
        "# Which employee(s) earn(s) a salary of more than 30000\n",
        "# OUR CODE GOES HERE\n",
        "\n",
        "# Which employee(s) earn(s) a salary of less than 30000 and joined before 2015\n",
        "# OUR CODE GOES HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ-lM05NsOfM"
      },
      "source": [
        "# Challenge 2\n",
        "# Find out the person with greatest age from the Dataframe that you will create\n",
        "# upon creating the Dictionary below\n",
        "# \n",
        "\n",
        "# Create a DataFrame\n",
        "df = {'Name':['Audrey','Kwasi','Parul','Lohinee','James','Catherine',\n",
        "'Val','Robert','Alex','Alisa','Murkomen','Judy'],\n",
        "'Age':[26,24,23,22,23,24,26,24,22,23,24,24],\n",
        "'Score':[85,63,55,74,31,77,85,63,42,62,89,77]}\n",
        "\n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1h4cB76sPbm"
      },
      "source": [
        "# Challenge 3\n",
        "# Get the unique values of the continent column from the Dataset below\n",
        "# url = http://bit.ly/FiveYearData\n",
        "#\n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg4YYl3esQt6"
      },
      "source": [
        "# Challenge 4\n",
        "# How many countries are there in the dataset on challenge 3\n",
        "# \n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRwUwGONsRr3"
      },
      "source": [
        "# Challenge 5\n",
        "# What is the average number of goals per teams from the dictionary below\n",
        "# \n",
        "\n",
        "# Creating our dataframe\n",
        "football = {'Team':['Arsenal', 'Manchester United', 'Arsenal', \n",
        "                   'Arsenal', 'Chelsea', 'Manchester United', \n",
        "                   'Manchester United', 'Chelsea', 'Chelsea', 'Chelsea'],     \n",
        "           'Player':['Ozil', 'Pogba', 'Lucas', 'Aubameyang', \n",
        "                       'Hazard', 'Mata', 'Lukaku', 'Morata',  \n",
        "                                         'Giroud', 'Kante'],                          \n",
        "           'Goals':[6, 4, 7, 5, 10, 3, 1, 6, 3, 4]} \n",
        "\n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2opvjY3p6zc"
      },
      "source": [
        "## 1.3 Selecting and Sorting\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zZPvy29p9bE"
      },
      "source": [
        "# Example 1\n",
        "# In this section, we will select and sort our dataframes\n",
        "# We will start off by ranking Rows Of Pandas Dataframes as shown \n",
        "#\n",
        "\n",
        "# Creating dataframe\n",
        "data = {'name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n",
        "        'year': [2012, 2012, 2013, 2014, 2014], \n",
        "        'reports': [4, 24, 31, 2, 3],\n",
        "        'coverage': [25, 94, 57, 62, 70]}\n",
        "df = pd.DataFrame(data, index = ['Cochice', 'Pima', 'Santa Cruz', 'Maricopa', 'Yuma'])\n",
        "df\n",
        "\n",
        "# Creating a new column that is the rank of the value of coverage in ascending order\n",
        "# Uncomment the line below after running previous lines\n",
        "df['coverageRanked'] = df['coverage'].rank(ascending=1)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLhFrqNiqWDX"
      },
      "source": [
        "# Example 2\n",
        "# Next, we will Select Rows When Columns that Contain Certain Values\n",
        "# \n",
        "\n",
        "# Create an example dataframe\n",
        "data = {'name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n",
        "        'year': [2012, 2012, 2013, 2014, 2014], \n",
        "        'reports': [4, 24, 31, 2, 3]}\n",
        "df = pd.DataFrame(data, index = ['Cochice', 'Pima', 'Santa Cruz', 'Maricopa', 'Yuma'])\n",
        "df\n",
        "\n",
        "# Get rows where column has certain values\n",
        "# Uncomment the line below after running previous lines\n",
        "# value_list = ['Tina', 'Molly', 'Jason']\n",
        "# df[df.name.isin(value_list)]\n",
        "\n",
        "# Get rows where column doesn't have certain values\n",
        "# Uncomment the line below after running previous lines\n",
        "# df[~df.name.isin(value_list)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8wjaHL3qV-1"
      },
      "source": [
        "# Example 3\n",
        "# Then, Select Rows With A Certain Value\n",
        "\n",
        "# Create an example dataframe\n",
        "data = {'name': ['Jason', 'Molly'], \n",
        "        'country': [['Syria', 'Lebanon'],['Spain', 'Morocco']]}\n",
        "df = pd.DataFrame(data)\n",
        "df\n",
        "\n",
        "# Uncomment the line below after running previous lines\n",
        "# df[df['country'].map(lambda country: 'Syria' in country)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGiiPkCvqu_W"
      },
      "source": [
        "# Example 4\n",
        "# Select Rows With Multiple Filters\n",
        "#\n",
        "\n",
        "# Create an example dataframe\n",
        "data = {'name': ['A', 'B', 'C', 'D', 'E'], \n",
        "        'score': [1,2,3,4,5]}\n",
        "df = pd.DataFrame(data)\n",
        "df\n",
        "\n",
        "# Select rows of the dataframe where df.score is greater than 1 and less and 5\n",
        "# Uncomment the line below after running previous lines\n",
        "# df[(df['score'] > 1) & (df['score'] < 5)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZb_iZhpqZ0T"
      },
      "source": [
        "# Example 5\n",
        "# Selecting DataFrame Rows Based On Conditions\n",
        "# \n",
        "\n",
        "# import numpy\n",
        "import numpy as np\n",
        "\n",
        "# Creating a dataframe\n",
        "raw_data = {'first_name': ['Jason', 'Molly', np.nan, np.nan, np.nan], \n",
        "        'nationality': ['USA', 'USA', 'France', 'UK', 'UK'], \n",
        "        'age': [42, 52, 36, 24, 70]}\n",
        "df = pd.DataFrame(raw_data, columns = ['first_name', 'nationality', 'age'])\n",
        "df\n",
        "\n",
        "# Method 1: Using Boolean Variables\n",
        "# Create variable with TRUE if nationality is USA\n",
        "# Uncomment the line below after running previous lines\n",
        "# american = df['nationality'] == \"USA\"\n",
        "\n",
        "# Create variable with TRUE if age is greater than 50\n",
        "# Uncomment the line below after running previous lines\n",
        "# elderly = df['age'] > 50\n",
        "\n",
        "# Select all cases where nationality is USA and age is greater than 50\n",
        "# Uncomment the line below after running previous lines \n",
        "# df[american & elderly]\n",
        "\n",
        "\n",
        "# Method 2: Using variable attributes\n",
        "# Select all cases where the first name is not missing and nationality is USA\n",
        "# Uncomment the line below after running previous lines\n",
        "# df[df['first_name'].notnull() & (df['nationality'] == \"USA\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q-WUNwOqxgj"
      },
      "source": [
        "# Example 6\n",
        "# Sorting Rows In pandas Dataframes\n",
        "# \n",
        "\n",
        "# Creating a Dataframe to work with\n",
        "data = {'name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n",
        "        'year': [2012, 2012, 2013, 2014, 2014], \n",
        "        'reports': [1, 2, 1, 2, 3],\n",
        "        'coverage': [2, 2, 3, 3, 3]}\n",
        "df = pd.DataFrame(data, index = ['Cochice', 'Pima', 'Santa Cruz', 'Maricopa', 'Yuma'])\n",
        "df\n",
        "\n",
        "# Sort the dataframe’s rows by reports, in descending order\n",
        "# Uncomment the line below after running previous lines\n",
        "# df.sort_values(by='reports', ascending=0)\n",
        "\n",
        "# Sort the dataframe’s rows by coverage and then by reports, in ascending order\n",
        "# Uncomment the line below after running previous lines\n",
        "# df.sort_values(by=['coverage', 'reports'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfpO_aWfsXXQ"
      },
      "source": [
        "### <font color=\"green\">1.3 Challenges</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwS81YKwscx6"
      },
      "source": [
        "# Challenge 1\n",
        "# Create a new column ranking the following cars by price \n",
        "# \n",
        "\n",
        "Cars = {'Brand': ['Honda Civic', 'Toyota Corolla', 'Ford Focus', 'Audi A4'],\n",
        "        'Price': [22000, 25000, 27000, 35000],\n",
        "        'Year': [2015, 2013, 2018, 2018]}\n",
        "\n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4SFJY8Xsd8p"
      },
      "source": [
        "# Challenge 2\n",
        "# Let's get the rows when the column contains certain values\n",
        "#\n",
        "\n",
        "data = {'model': ['Lisa', 'Lisa 2', 'Macintosh 128K', 'Macintosh 512K'],\n",
        "        'launched': [1983, 1984, 1984, 1984],\n",
        "        'discontinued': [1986, 1985, 1984, 1986]}\n",
        "columns = ['model', 'launched', 'discontinued']\n",
        "\n",
        "# Get the rows where the column model contains Lisa\n",
        "OUR CODE GOES HERE\n",
        "\n",
        "# Get the rows where the column model does not contain Macintosh 128K\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUZfz_79sfJO"
      },
      "source": [
        "# Challenge 3\n",
        "# Select the rows with the value blue or yellow from the Dataframe below\n",
        "#\n",
        "data = {'name': ['Willam', 'Alex', 'Oliech', 'Julie'],\n",
        "'age': [20, 19, 22, 21],\n",
        "'favorite_color': ['blue', 'blue', 'yellow', \"green\"],\n",
        "'grade': [88, 92, 95, 70]}\n",
        "\n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXMrd5EUsgMY"
      },
      "source": [
        "# Challenge 4\n",
        "# Using the following dataset, which counties have less than 50,000 households?\n",
        "# url = http://bit.ly/KeHouseholds1\n",
        "# This dataset shows the distribution of households based on their age group, gender and household head.\n",
        "#\n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUd5qnwashOE"
      },
      "source": [
        "# Challenge 5\n",
        "# Using the following dataset, Which top 3 municipalities have the highest population?\n",
        "# url = http://bit.ly/KePopulationDistribution1\n",
        "# \n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d79MaLZ6si_o"
      },
      "source": [
        "# Challenge 6\n",
        "# Using the dataset given in challenge 5, sort the rows by the total core urban population \n",
        "#\n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XzRgbIzBJ6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "03d20023-1d09-4d91-d6c4-ef7f847d31a9"
      },
      "source": [
        "# Challenge 7\n",
        "# Using the following dataset, Which quarter experienced the highest no. of visitors after 2007\n",
        "# url = http://bit.ly/VisitorsToKenya\n",
        "# This dataset comprises of visitor arrivals and departures Between 1991 up to 2014 by the purpose of visiting Kenya\n",
        "# \n",
        "# OUR CODE GOES HERE\n",
        "import pandas as pd\n",
        "\n",
        "tst  = pd.read_csv(\"http://bit.ly/VisitorsToKenya\", delimiter=\"\\s+\", )\n",
        "tst.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-fe576480fe83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtst\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"http://bit.ly/VisitorsToKenya\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\s+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'infer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2035\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2037\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2038\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 51 fields in line 128, saw 524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwxDABvUp97g"
      },
      "source": [
        "## 1.4 Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yj3yDXQqbR2"
      },
      "source": [
        "# Example 1\n",
        "# Assign a new column to a Pandas DataFrame\n",
        "# \n",
        "\n",
        "# Create empty dataframe\n",
        "df = pd.DataFrame() \n",
        "df['name'] = ['John', 'Steve', 'Sarah'] \n",
        "df\n",
        " \n",
        "# Assign a new column to df called 'age' with a list of ages\n",
        "# Uncomment the line below after running previous lines\n",
        "# df.assign(age = [31, 32, 19]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m05L3x9YqbJa"
      },
      "source": [
        "# Example 2\n",
        "# Lowercase column names in Pandas Dataframe\n",
        "#\n",
        "\n",
        "# Let's first set ipython's max row display\n",
        "pd.set_option('display.max_row', 1000)\n",
        "\n",
        "# Let's first set iPython's max column width to 50\n",
        "pd.set_option('display.max_columns', 50)\n",
        "\n",
        "# Create an example dataframe\n",
        "data = {'NAME': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n",
        "        'YEAR': [2012, 2012, 2013, 2014, 2014], \n",
        "        'REPORTS': [4, 24, 31, 2, 3]}\n",
        "df = pd.DataFrame(data, index = ['Cochice', 'Pima', 'Santa Cruz', 'Maricopa', 'Yuma'])\n",
        "df\n",
        " \n",
        "# Map the lowering function to all column names\n",
        "# Uncomment the line below after running previous lines\n",
        "# df.columns = map(str.lower, df.columns)\n",
        "# df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo5k1y_7qBto"
      },
      "source": [
        "# Example 3\n",
        "# While doing data analysis, finding duplicates in your data is very important. \n",
        "# Delete duplicates in pandas\n",
        "#\n",
        "\n",
        "\n",
        "# Create dataframe with duplicates\n",
        "raw_data = {'first_name': ['Jason', 'Jason', 'Jason','Tina', 'Jake', 'Amy'], \n",
        "        'last_name': ['Miller', 'Miller', 'Miller','Ali', 'Milner', 'Cooze'], \n",
        "        'age': [42, 42, 1111111, 36, 24, 73], \n",
        "        'preTestScore': [4, 4, 4, 31, 2, 3],\n",
        "        'postTestScore': [25, 25, 25, 57, 62, 70]}\n",
        "df = pd.DataFrame(raw_data, columns = ['first_name', 'last_name', 'age', 'preTestScore', 'postTestScore'])\n",
        "df\n",
        "\n",
        "# Identify which observations are duplicates\n",
        "# Uncomment the line below after running previous lines\n",
        "# df.duplicated()\n",
        "\n",
        "# Drop duplicates\n",
        "# Uncomment the line below after running previous lines\n",
        "# df.drop_duplicates()\n",
        "\n",
        "# Drop duplicates in a specific column\n",
        "# Uncomment the line below after running previous lines\n",
        "# df.drop_duplicates(['first_name'], keep='last')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuVreA2DqCuS"
      },
      "source": [
        "# Example 4\n",
        "# Another crucial part of data analysis is finding missing data and deleting them. Let's lookd at how to deal with missing data \n",
        "# Missing data in pandas Dataframes\n",
        "#\n",
        "\n",
        "raw_data = {'first_name': ['Jason', np.nan, 'Tina', 'Jake', 'Amy'], \n",
        "        'last_name': ['Miller', np.nan, 'Ali', 'Milner', 'Cooze'], \n",
        "        'age': [42, np.nan, 36, 24, 73], \n",
        "        'sex': ['m', np.nan, 'f', 'm', 'f'], \n",
        "        'preTestScore': [4, np.nan, np.nan, 2, 3],\n",
        "        'postTestScore': [25, np.nan, np.nan, 62, 70]}\n",
        "df = pd.DataFrame(raw_data, columns = ['first_name', 'last_name', 'age', 'sex', 'preTestScore', 'postTestScore'])\n",
        "df\n",
        "\n",
        "# Checking if there are missing values in your data\n",
        "# Uncomment the line below after running previous lines\n",
        "# df.isnull() #returns a boolean value for all the cells that have Nan  value\n",
        "\n",
        "\n",
        "# Drop missing observations\n",
        "# Uncomment the line below after running previous lines\n",
        "# df_no_missing = df.dropna()\n",
        "# df_no_missing\n",
        "\n",
        "# Drop rows where all cells in that row is NA\n",
        "# Uncomment the line below after running previous lines\n",
        "# df_cleaned = df.dropna(how='all')\n",
        "# df_cleaned\n",
        "\n",
        "# Drop column if they only contain missing values\n",
        "# Uncomment the line below after running previous lines\n",
        "# df.dropna(axis=1, how='all')\n",
        "\n",
        "# Drop rows that contain less than five observations\n",
        "# Uncomment the line below after running previous lines\n",
        "# df.dropna(thresh=5)\n",
        "\n",
        "# Fill in missing data with zeros\n",
        "# Uncomment the line below after running previous lines\n",
        "# df.fillna(0)\n",
        "\n",
        "# Fill in missing in preTestScore with the mean value of preTestScore\n",
        "# Uncomment the line below after running previous lines\n",
        "# df[\"preTestScore\"].fillna(df[\"preTestScore\"].mean(), inplace=True)\n",
        "# df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_7vT83gq0TP"
      },
      "source": [
        "# Example 5\n",
        "# Dropping rows and columns in pandas Dataframe\n",
        "#\n",
        "\n",
        "# Create a dataframe\n",
        "data = {'name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n",
        "        'year': [2012, 2012, 2013, 2014, 2014], \n",
        "        'reports': [4, 24, 31, 2, 3]}\n",
        "df = pd.DataFrame(data, index = ['Cochice', 'Pima', 'Santa Cruz', 'Maricopa', 'Yuma'])\n",
        "df\n",
        "\n",
        "# Drop an observation (row)\n",
        "# Uncomment the line below after running previous lines\n",
        "# df.drop(['Cochice', 'Pima'])\n",
        "\n",
        "# Drop a variable (column). \n",
        "# NB: axis=1 denotes that we are referring to a column, not a row\n",
        "# Uncomment the line below after running previous lines\n",
        "# df.drop('reports', axis=1)\n",
        "\n",
        "# Drop a row if it contains a certain value (in this case, “Tina”)\n",
        "# Create a new dataframe called df that includes all rows where \n",
        "# the value of a cell in the name column does not equal “Tina”\n",
        "# Uncomment the line below after running previous lines\n",
        "# df[df.name != 'Tina']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66Fjm3xmslG7"
      },
      "source": [
        "### <font color=\"green\">1.4 Challenges</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH_6cmIostHA"
      },
      "source": [
        "# Challenge 1\n",
        "# Let's assign the new column address to the created dataframe frow the dictionary below\n",
        "#\n",
        "\n",
        "# Define a dictionary containing Students data \n",
        "finals = {'Name': ['Robert', 'Thomas', 'Susan', 'Irene'], \n",
        "        'Height': [5.1, 6.2, 5.1, 5.2], \n",
        "        'Qualification': ['Msc', 'MA', 'Msc', 'Msc']} \n",
        "address = ['UoN', 'Strathmore', 'JKUAT', 'JKUAT'] \n",
        "\n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73tUDU64stqu"
      },
      "source": [
        "# Challenge 2\n",
        "# Let us lowercase the column names in the following dataset\n",
        "# url = http://bit.ly/KePopulationDistribution1\n",
        "#\n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q0-ybtZstks"
      },
      "source": [
        "# Challenge 3\n",
        "# Delete duplicate values from the dictionary below\n",
        "# \n",
        "\n",
        "# First creating the following DataFrame\n",
        "d = {\n",
        "    'Name':['Alice','Brian','Rhoda','Pauline','Julius','Catherine',\n",
        "            'Alice','Brian','Kellen','Alice','Alex','Yvonne'],\n",
        "    'Age':[26,24,23,22,23,24,26,24,22,23,24,24],\n",
        "    'Score':[85,63,55,74,31,77,85,63,42,62,89,77]}\n",
        "\n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54xutk3fstfP"
      },
      "source": [
        "# Challenge 4\n",
        "# Drop the missing columns \n",
        "#\n",
        "\n",
        "# Creating our DataFrame\n",
        "df = {'Name':['George','Andrea','micheal','maggie','Ravi','Xien','Jalpa',np.nan],\n",
        "    'State':['Arizona','Georgia','Newyork','Indiana','Florida','California',np.nan,np.nan],\n",
        "    'Gender':[\"M\",\"F\",\"M\",\"F\",\"M\",\"M\",np.nan,np.nan],      \n",
        "    'Score':[63,48,56,75,np.nan,77,np.nan,np.nan]}\n",
        "\n",
        "# Drop all rows that have any NaN (missing) values\n",
        "OUR CODE GOES HERE\n",
        "\n",
        "# Drop records which have more than 2 missing values\n",
        "OUR CODE GOES HERE\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-4ZiKtrsySp"
      },
      "source": [
        "# Challenge 5\n",
        "# Using the following dataset given, get the records which contain missing observations,\n",
        "# then make a decision which records to delete based on the context.\n",
        "# Act on the decision taken (i.e. Drop/Not dropping) and state your decision below\n",
        "# url = http://bit.ly/KePopulationDistribution1\n",
        "# \n",
        "\n",
        "OUR CODE GOES HERE\n",
        "\n",
        "# Decision Taken:\n",
        "# YOUR DECISION GOES HERE\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jHC3c0jqFHy"
      },
      "source": [
        "## 1.5 Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avpOVTs-qIPl"
      },
      "source": [
        "# Example 1\n",
        "# Descriptive Statistics For pandas Dataframe\n",
        "#\n",
        "\n",
        "data = {'name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n",
        "        'age': [42, 52, 36, 24, 73], \n",
        "        'preTestScore': [4, 24, 31, 2, 3],\n",
        "        'postTestScore': [25, 94, 57, 62, 70]}\n",
        "df = pd.DataFrame(data, columns = ['name', 'age', 'preTestScore', 'postTestScore'])\n",
        "df\n",
        "\n",
        "\n",
        "# The sum of all the ages\n",
        "# Uncomment the line below after running previous lines\n",
        "# df['age'].sum()\n",
        "\n",
        "# Mean preTestScore\n",
        "# Uncomment the line below after running previous lines\n",
        "# df['preTestScore'].mean()\n",
        "\n",
        "# Cumulative sum of preTestScores, moving from the rows from the top\n",
        "# Uncomment the line below after running previous lines\n",
        "# df['preTestScore'].cumsum()\n",
        "\n",
        "# Summary statistics on preTestScore\n",
        "# Uncomment the line below after running previous lines.\n",
        "# The output for this summary will be; the total number of rows there is in the column, the mean value for the data in the column, \n",
        "# the standard deviation of the data , min and max values of the data, the 25th 50th 75th percentile of the data.\n",
        "df['preTestScore'].describe()\n",
        "\n",
        "# Count the number of non-NA values\n",
        "# Uncomment the line below after running previous lines\n",
        "# df['preTestScore'].count()\n",
        "\n",
        "# Minimum value of preTestScore\n",
        "# Uncomment the line below after running previous lines\n",
        "# df['preTestScore'].min()\n",
        "\n",
        "# Maximum value of preTestScore\n",
        "# Uncomment the line below after running previous lines\n",
        "# df['preTestScore'].max()\n",
        "\n",
        "# Median value of preTestScore\n",
        "# Uncomment the line below after running previous lines\n",
        "# df['preTestScore'].median()\n",
        "\n",
        "# Sample variance of preTestScore values\n",
        "# Uncomment the line below after running previous lines\n",
        "# df['preTestScore'].var()\n",
        "\n",
        "# Sample standard deviation of preTestScore values\n",
        "# Uncomment the line below after running previous lines\n",
        "# df['preTestScore'].std()\n",
        "\n",
        "# Skewness of preTestScore values\n",
        "# Uncomment the line below after running previous lines\n",
        "# df['preTestScore'].skew()\n",
        "\n",
        "# Kurtosis of preTestScore values\n",
        "# Uncomment the line below after running previous lines\n",
        "# df['preTestScore'].kurt()\n",
        "\n",
        "# Correlation Matrix Of Values\n",
        "# A correlation matrix is a table showing correlation coefficents of different variables. In other words, it shows how different columns corelate to each other. The coefficients range between -1 and 1.\n",
        "# The closer the values are to -1 indicates that the variables do not correlate while the closer the values are to 1 indicates that the values have a high correlation.\n",
        "# A correlation matrix is very important when we are trying to understand our data as it serves as input for advanced analysis.\n",
        "# Uncomment the line below after running previous lines\n",
        "# df.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7rE9W05qIGH"
      },
      "source": [
        "# Example 2\n",
        "# Apply Operations To Groups In Pandas\n",
        "#\n",
        "\n",
        "# Create dataframe\n",
        "raw_data = {'regiment': ['Nighthawks', 'Nighthawks', 'Nighthawks', 'Nighthawks', 'Dragoons', 'Dragoons', 'Dragoons', 'Dragoons', 'Scouts', 'Scouts', 'Scouts', 'Scouts'], \n",
        "        'company': ['1st', '1st', '2nd', '2nd', '1st', '1st', '2nd', '2nd','1st', '1st', '2nd', '2nd'], \n",
        "        'name': ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze', 'Jacon', 'Ryaner', 'Sone', 'Sloan', 'Piger', 'Riani', 'Ali'], \n",
        "        'preTestScore': [4, 24, 31, 2, 3, 4, 24, 31, 2, 3, 2, 3],\n",
        "        'postTestScore': [25, 94, 57, 62, 70, 25, 94, 57, 62, 70, 62, 70]}\n",
        "df = pd.DataFrame(raw_data, columns = ['regiment', 'company', 'name', 'preTestScore', 'postTestScore'])\n",
        "df\n",
        "\n",
        "# Create a groupby variable that groups preTestScores by regiment\n",
        "# Uncomment the line below after running previous lines\n",
        "# groupby_regiment = df['preTestScore'].groupby(df['regiment'])\n",
        "# groupby_regiment\n",
        "\n",
        "# Descriptive statistics by group\n",
        "# Uncomment the line below after running previous lines\n",
        "# df['preTestScore'].groupby(df['regiment']).describe()\n",
        "\n",
        "# Mean of each regiment’s preTestScore\n",
        "# Uncomment the line below after running previous lines\n",
        "# groupby_regiment.mean()\n",
        "\n",
        "# Mean preTestScores grouped by regiment and company\n",
        "# Uncomment the line below after running previous lines\n",
        "# df['preTestScore'].groupby([df['regiment'], df['company']]).mean()\n",
        "\n",
        "# Number of observations in each regiment and company\n",
        "# Uncomment the line below after running previous lines\n",
        "# df.groupby(['regiment', 'company']).size()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmExhKs_qjNX"
      },
      "source": [
        "# Example 3\n",
        "# Random Sampling Dataframe\n",
        "# \n",
        "\n",
        "raw_data = {'first_name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n",
        "        'last_name': ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze'], \n",
        "        'age': [42, 52, 36, 24, 73], \n",
        "        'preTestScore': [4, 24, 31, 2, 3],\n",
        "        'postTestScore': [25, 94, 57, 62, 70]}\n",
        "df = pd.DataFrame(raw_data, columns = ['first_name', 'last_name', 'age', 'preTestScore', 'postTestScore'])\n",
        "df\n",
        "\n",
        "# Select a random subset of 2 without replacement\n",
        "# Uncomment the line below after running previous lines\n",
        "# df.take(np.random.permutation(len(df))[:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHg3qJbYq4iY"
      },
      "source": [
        "# Example 4\n",
        "# Pivot Tables In pandas\n",
        "#\n",
        "\n",
        "# Create dataframe\n",
        "raw_data = {'regiment': ['Nighthawks', 'Nighthawks', 'Nighthawks', 'Nighthawks', 'Dragoons', 'Dragoons', 'Dragoons', 'Dragoons', 'Scouts', 'Scouts', 'Scouts', 'Scouts'], \n",
        "        'company': ['1st', '1st', '2nd', '2nd', '1st', '1st', '2nd', '2nd','1st', '1st', '2nd', '2nd'], \n",
        "        'TestScore': [4, 24, 31, 2, 3, 4, 24, 31, 2, 3, 2, 3]}\n",
        "df = pd.DataFrame(raw_data, columns = ['regiment', 'company', 'TestScore'])\n",
        "df\n",
        "\n",
        "# Create a pivot table of group means, by company and regiment\n",
        "# Uncomment the line below after running previous lines\n",
        "# pd.pivot_table(df, index=['regiment','company'], aggfunc='mean')\n",
        "\n",
        "# Create a pivot table of group score counts, by company and regiments\n",
        "# Uncomment the line below after running previous lines\n",
        "# df.pivot_table(index=['regiment','company'], aggfunc='count')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOI_UEXDs0XI"
      },
      "source": [
        "### <font color=\"green\">1.5 Challenges</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK1ar12Ks7xI"
      },
      "source": [
        "# Challenge 1\n",
        "# Using the given dataset, calculate the descriptive statistics of the total population\n",
        "# url = http://bit.ly/KePopulationDistribution1\n",
        "#\n",
        "\n",
        "# The total population in Kenya\n",
        "OUR CODE GOES HERE\n",
        "\n",
        "# The average population per urban center \n",
        " \n",
        "\n",
        "# The total urban population fo the cities \n",
        " \n",
        "\n",
        "# Summary statistics on total population\n",
        " \n",
        "\n",
        "# Count the number municipalities in the country\n",
        "\n",
        "\n",
        "# Which municipality/city/other/town is the most sparcely populated \n",
        "\n",
        "\n",
        "# Which municipality/city/other/town is the most densely populated \n",
        "\n",
        "# Median value of the total population \n",
        "\n",
        "\n",
        "# Sample variance of the total population\n",
        "\n",
        "\n",
        "# Sample standard deviation of the total population\n",
        "\n",
        "\n",
        "# Correlation of the variables in the given dataset\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8WhwyH2s9VI"
      },
      "source": [
        "# Challenge 2\n",
        "# Using the given dictionary below, find out the mean and median of the points during the Years\n",
        "# \n",
        "\n",
        "kenyan_premier_league = {'Team': ['Gor Mahia', 'AFC', 'Mathare', 'Ushuru', 'Kariobangi Sharks',\n",
        "   'Tusker', 'Bandari', 'Mumias', 'Thika Utd', 'Kakamega', 'Nakuru Utd', 'Kibera Utd'], \n",
        "   'Year': [2018, 2019, 2017, 2019, 2017, 2019, 2016, 2017, 2016, 2018, 2019, 2017],\n",
        "   'Points':[87, 78, 86, 67, 74, 81, 75, 78, 69, 70, 80, 69]}\n",
        "\n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RqruGXas-pK"
      },
      "source": [
        "# Challenge 3\n",
        "# Randomly select a municipality without replacement from the following dataset\n",
        "# url = http://bit.ly/KePopulationDistribution1\n",
        "# \n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSmCEJ2etAjt"
      },
      "source": [
        "# Challenge 4\n",
        "# From the given dataset, create a pivot table of sum total population by District \n",
        "#\n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giPMZ4IetBne"
      },
      "source": [
        "# Challenge 5\n",
        "# From the given dataset, create a pivot table of sum total population by District \n",
        "# url = http://bit.ly/KePopulationDistribution1\n",
        "# \n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}